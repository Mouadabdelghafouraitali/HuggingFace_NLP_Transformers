{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4646c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f8a58a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Amazing customer service phrase is POSITIVE with confidence percentage up to 99.99%\n",
      "The Low quality and bad service phrase is NEGATIVE with confidence percentage up to 99.98%\n",
      "The خدمة عملاء جيدة phrase is POSITIVE with confidence percentage up to 65.1%\n",
      "The جودة منخفضة وخدمة سيئة phrase is NEGATIVE with confidence percentage up to 86.34%\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "#English\n",
    "phrase = \"Amazing customer service\"\n",
    "result = classifier(phrase)[0]\n",
    "\n",
    "print(\"The {} phrase is {} with confidence percentage up to {}%\".format(phrase,result['label'],round(result['score']*100, 2)))\n",
    "\n",
    "phrase = \"Low quality and bad service\"\n",
    "result = classifier(phrase)[0]\n",
    "\n",
    "print(\"The {} phrase is {} with confidence percentage up to {}%\".format(phrase,result['label'],round(result['score']*100, 2)))\n",
    "\n",
    "\n",
    "\n",
    "#Arabic\n",
    "#classifier = pipeline(\"sentiment-analysis\", model =\"bert-base-multilingual-cased\")\n",
    "\n",
    "phrase = \"خدمة عملاء جيدة\"\n",
    "result = classifier(phrase)[0]\n",
    "\n",
    "print(\"The {} phrase is {} with confidence percentage up to {}%\".format(phrase,result['label'],round(result['score']*100, 2)))\n",
    "\n",
    "phrase = \"جودة منخفضة وخدمة سيئة\"\n",
    "result = classifier(phrase)[0]\n",
    "\n",
    "print(\"The {} phrase is {} with confidence percentage up to {}%\".format(phrase,result['label'],round(result['score']*100, 2)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "514ece62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1be18f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't believe I'm doing this. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "لا أصدق أن الكتاب لم يكن كما توقعته. و لكن الكتاب لم يكن كما توقعت. و لم يعجبني في الكتاب. و لم يعجبني في الكتاب. و لم يعجبني في الكتاب. و لم يعجبني في الكتاب أن الكتاب لم يعجبني كثيراً و لم يعجبني في\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#English\n",
    "text_generation = pipeline(\"text-generation\")\n",
    "generated_text= text_generation(\"I can't believe\", max_length=50, do_sample=False)[0]\n",
    "print(generated_text[\"generated_text\"])\n",
    "\n",
    "#Arabic\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mofawzy/gpt2-arabic-sentence-generator\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mofawzy/gpt2-arabic-sentence-generator\")\n",
    "text_generation = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "generated_text= text_generation(\"لا أصدق\", max_length=50, do_sample=False)[0]\n",
    "print(generated_text['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9745300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a148ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"ner\")\n",
    "\n",
    "sequence = \"Google LLC is an American multinational technology company that specializes in Internet-related services and products, which include online advertising technologies, a search engine, cloud computing, software, and hardware\"\n",
    "\n",
    "print(nlp(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "481feae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0a50ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6855362057685852, 'start': 12, 'end': 37, 'answer': 'a mobile operating system'}\n",
      "{'score': 0.65392005443573, 'start': 141, 'end': 167, 'answer': 'touchscreen mobile devices'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"question-answering\")\n",
    "\n",
    "context = r\"\"\"\n",
    "Android is a mobile operating system based on a modified version of the Linux kernel and other open source software, designed primarily for touchscreen mobile devices such as smartphones and tablets`.\n",
    "\"\"\"\n",
    "\n",
    "print(nlp(question=\"What is Android?\", context=context))\n",
    "print(nlp(question=\"Android desinged for?\", context=context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8a4a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling masked text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "649ce9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sequence': 'Facebook is making people talk to each other.', 'score': 0.20649941265583038, 'token': 1067, 'token_str': ' talk'}, {'sequence': 'Facebook is making people nicer to each other.', 'score': 0.16319316625595093, 'token': 35735, 'token_str': ' nicer'}, {'sequence': 'Facebook is making people listen to each other.', 'score': 0.08909185975790024, 'token': 4161, 'token_str': ' listen'}, {'sequence': 'Facebook is making people invisible to each other.', 'score': 0.062384217977523804, 'token': 20731, 'token_str': ' invisible'}, {'sequence': 'Facebook is making people mean to each other.', 'score': 0.050037335604429245, 'token': 1266, 'token_str': ' mean'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"fill-mask\")\n",
    "print(nlp(f\"Facebook is making people {nlp.tokenizer.mask_token} to each other.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1082d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "full_text = \"\"\"Android isn’t a phone or an application, but an operating system based on the Linux kernel. No clue what that is? In its most simple definition, Linux is an operating system most commonly found on servers and desktop computers. Android isn’t just a Linux version, due to the many changes found under the hood, but it’s related.\n",
    "Android is an operating system designed with mobility in mind. It’s also the place where your phone’s functions and applications live. Everything you see on the display of your device is a part of the operating system. When you get a call, text message, or email, the OS processes that information and puts it in an understandable format.\n",
    "\"\"\"\n",
    "summary = summarizer(full_text, max_length=130, min_length=30)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9c0f95f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731dbcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation_en_to_fr\")\n",
    "print(translator(\"I can't fly, because I don't have wings\", max_length=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f713b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4eb18a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "feature_extraction = pipeline('feature-extraction', model=\"distilroberta-base\", tokenizer=\"distilroberta-base\")\n",
    "features = feature_extraction(\"Instagram is an American photo and video sharing social networking service created by Kevin Systrom and Mike Krieger. In April 2012\")\n",
    "print(len(features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fec7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
